{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0444e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim as slim\n",
    "\n",
    "\n",
    "def leaky_relu(x, lk = 0.2):\n",
    "\treturn tf.maximum(x, x * lk)\n",
    "\n",
    "def _fixed_padding(inputs, kernel_size, rate=1):\n",
    "\tkernel_size_effective = [kernel_size[0] + (kernel_size[0] - 1) * (rate - 1),\n",
    "\t\t\t\t\t\t\tkernel_size[0] + (kernel_size[0] - 1) * (rate - 1)]\n",
    "\tpad_total = [kernel_size_effective[0] - 1, kernel_size_effective[1] - 1]\n",
    "\tpad_beg = [pad_total[0] // 2, pad_total[1] // 2]\n",
    "\tpad_end = [pad_total[0] - pad_beg[0], pad_total[1] - pad_beg[1]]\n",
    "\tpadded_inputs = tf.pad(inputs, [[0, 0], [pad_beg[0], pad_end[0]],\n",
    "\t\t\t\t\t\t[pad_beg[1], pad_end[1]], [0, 0]], mode='SYMMETRIC')\n",
    "\treturn padded_inputs\n",
    "\n",
    "\n",
    "DL1C = 256\n",
    "DL2C = 512\n",
    "\n",
    "discriminator_cfg_p9 = {\n",
    "\t'l_num': 2,\n",
    "\t'l0_c': 3,                           # 216\n",
    "\t'l1_c': DL1C,   'l1_k': 3, 'l1_s': 3, # 72\n",
    "\t'l2_c': DL2C,   'l2_k': 3, 'l2_s': 3, # 24\n",
    "}\n",
    "\n",
    "discriminator_cfg_p12 = {\n",
    "\t'l_num': 2,\n",
    "\t'l0_c': 3,                           # 240\n",
    "\t'l1_c': DL1C,   'l1_k': 4, 'l1_s': 4, # 60\n",
    "\t'l2_c': DL2C,   'l2_k': 3, 'l2_s': 3, # 20\n",
    "}\n",
    "\n",
    "discriminator_cfg_p15 = {\n",
    "\t'l_num': 2,\n",
    "\t'l0_c': 3,                           # 240\n",
    "\t'l1_c': DL1C,   'l1_k': 5, 'l1_s': 5, # 48\n",
    "\t'l2_c': DL2C,   'l2_k': 3, 'l2_s': 3, # 16\n",
    "}\n",
    "\n",
    "discriminator_cfg_p16 = {\n",
    "\t'l_num': 2,\n",
    "\t'l0_c': 3,                           # 256\n",
    "\t'l1_c': DL1C,   'l1_k': 4, 'l1_s': 4, # 64\n",
    "\t'l2_c': DL2C,   'l2_k': 4, 'l2_s': 4, # 16\n",
    "}\n",
    "\n",
    "supported_patch_size = {\n",
    "\t9 : discriminator_cfg_p9,\n",
    "\t12: discriminator_cfg_p12,\n",
    "\t15: discriminator_cfg_p15,\n",
    "\t16: discriminator_cfg_p16\n",
    "}\n",
    "\n",
    "batch_norm_decay=0.95\n",
    "batch_norm_epsilon=0.001\n",
    "batch_norm_updates_collections=tf.GraphKeys.UPDATE_OPS\n",
    "\n",
    "#changed reuse = False to reuse=tf.AUTO_REUSE\n",
    "#change it back\n",
    "def build_discriminator(inp, patch_size=9, is_training=True,\n",
    "\tname='discriminator', reuse=False):\n",
    "\td_state = inp\n",
    "\tbatch_norm_params = {\n",
    "\t\t'center': True,\n",
    "\t\t'scale': True,\n",
    "\t\t'decay': batch_norm_decay,\n",
    "\t\t'epsilon': batch_norm_epsilon,\n",
    "\t\t'updates_collections': batch_norm_updates_collections,\n",
    "\t\t'is_training': is_training\n",
    "\t}\n",
    "\twith slim.arg_scope([slim.batch_norm], **batch_norm_params):\n",
    "\t\twith tf.variable_scope(name, reuse=reuse):\n",
    "\t\t\t# conv s1\n",
    "\t\t\tcfg = supported_patch_size[patch_size]\n",
    "\t\t\twith slim.arg_scope([slim.conv2d],\n",
    "\t\t\t\tactivation_fn=leaky_relu,\n",
    "\t\t\t\tnormalizer_fn=slim.batch_norm,\n",
    "\t\t\t\tpadding='VALID'):\n",
    "\t\t\t\tfor l in range(1, cfg['l_num'] + 1):\n",
    "\t\t\t\t\td_state = slim.conv2d(d_state,\n",
    "\t\t\t\t\t\tcfg['l%d_c'%l],\n",
    "\t\t\t\t\t\t[cfg['l%d_k'%l], cfg['l%d_k'%l]],\n",
    "\t\t\t\t\t\tstride=cfg['l%d_s'%l], scope='s1_%d'%l)\n",
    "\t\t\td_state = slim.conv2d(d_state, 1, [1, 1], stride=1,\n",
    "\t\t\t\tactivation_fn=tf.nn.sigmoid, scope='patch_mat')\n",
    "\treturn d_state\n",
    "\n",
    "g_encoder_cfg = {\n",
    "\t'l_num': 3,\n",
    "\t'l0_c': 32,   'l0_k': 3, 'l0_s': 2, # 1/2  --------> sc1\n",
    "\t'l1_c': 64,   'l1_k': 3, 'l1_s': 2, # 1/4  --------> sc2\n",
    "\t'l2_c': 128,  'l2_k': 3, 'l2_s': 2  # 1/8  --------> sc3 -L\n",
    "}\n",
    "\n",
    "g_residual_cfg = {\n",
    "\t'l_num': 1,\n",
    "\t'c': 128, 'k': 3\n",
    "}\n",
    "\n",
    "g_decoder_cfg = {\n",
    "\t'l_num': 3,\n",
    "\t'l0_c': 64,  'l0_k': 3, 'l0_s': 2, # --- x2\n",
    "\t'l1_c': 32,  'l1_k': 3, 'l1_s': 2, # --- x4\n",
    "\t'l2_c': 16,  'l2_k': 3, 'l2_s': 2, # --- x8\n",
    "}\n",
    "\n",
    "g_skip_conn_cfg = {\n",
    "\t'l_num' : 2\n",
    "}\n",
    "\n",
    "#changed reuse = False to reuse=tf.AUTO_REUSE\n",
    "def build_generator(inp, name='generator', reuse=False):\n",
    "\tg_state = inp   # No prep\n",
    "\twith tf.variable_scope(name, reuse=reuse):\n",
    "\t\tcfg = g_encoder_cfg\n",
    "\t\tskip_conn = []\n",
    "\t\twith slim.arg_scope([slim.conv2d, slim.separable_conv2d], activation_fn=tf.nn.relu,\n",
    "\t\t\t\t\tnormalizer_fn=slim.instance_norm, padding='VALID'):\n",
    "\t\t\tfor index in range(cfg['l_num']):\n",
    "\t\t\t\tg_state = _fixed_padding(g_state, [cfg['l%d_k'%index]])\n",
    "\t\t\t\tg_state = slim.separable_conv2d(g_state, None, [cfg['l%d_k'%index], cfg['l%d_k'%index]],\n",
    "\t\t\t\t\tdepth_multiplier=1, stride=cfg['l%d_s'%index], scope='enc_%d_dw'%index)\n",
    "\t\t\t\tg_state = slim.conv2d(g_state, cfg['l%d_c'%index], [1, 1], stride=1, scope='enc_%d_pw'%index)\n",
    "\t\t\t\tskip_conn.append(g_state)\n",
    "\n",
    "\t\tcfg = g_residual_cfg\n",
    "\t\twith slim.arg_scope([slim.conv2d, slim.separable_conv2d], activation_fn=tf.nn.relu,\n",
    "\t\t\t\t\tnormalizer_fn=slim.instance_norm, padding='VALID'):\n",
    "\t\t\tfor index in range(cfg['l_num']):\n",
    "\t\t\t\tres_g = g_state\n",
    "\t\t\t\tg_state = _fixed_padding(g_state, [cfg['k']])\n",
    "\t\t\t\tg_state = slim.separable_conv2d(g_state, None, [cfg['k'], cfg['k']],\n",
    "\t\t\t\t\tdepth_multiplier=1, stride=1, scope='res_%d_dw'%index)\n",
    "\t\t\t\tg_state = slim.conv2d(g_state, cfg['c'], [1, 1], stride=1,\n",
    "\t\t\t\t\tactivation_fn=None, scope='res_%d_pw'%index)\n",
    "\t\t\t\tg_state = tf.nn.relu(g_state + res_g)\n",
    "\n",
    "\t\tcfg = g_decoder_cfg\n",
    "\t\twith slim.arg_scope([slim.conv2d, slim.separable_conv2d], activation_fn=None,\n",
    "\t\t\t\t\tnormalizer_fn=slim.instance_norm, padding='VALID'):\n",
    "\t\t\tfor index in range(cfg['l_num']):\n",
    "\t\t\t\tg_state = tf.image.resize_images(g_state,\n",
    "\t\t\t\t\t(g_state.shape[1]*2, g_state.shape[2]*2), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\t\t\t\tg_state = _fixed_padding(g_state, [cfg['l%d_k'%index]])\n",
    "\t\t\t\tg_state = slim.separable_conv2d(g_state, None,\n",
    "\t\t\t\t\t[cfg['l%d_k'%index], cfg['l%d_k'%index]], depth_multiplier=1, stride=1, scope='dec_%d_dw'%index)\n",
    "\t\t\t\tg_state = slim.conv2d(g_state, cfg['l%d_c'%index], [1, 1], stride=1, scope='dec_%d_pw'%index)\n",
    "\t\t\t\t# sc = slim.conv2d(skip_conn[?], 128, [1, 1], stride=1, scope='sc')\n",
    "\t\t\t\tif index < g_skip_conn_cfg['l_num']:\n",
    "\t\t\t\t\tg_state = tf.nn.relu(g_state + skip_conn[g_skip_conn_cfg['l_num'] - index - 1])\n",
    "\t\t\t\t\t#commented line above for debugging------------------------------\n",
    "\t\t\t\t\t#g_state = tf.nn.relu(g_state + skip_conn[min(g_skip_conn_cfg['l_num'] - 1, index)])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tg_state = tf.nn.relu(g_state)\n",
    "\t\tg_state = _fixed_padding(g_state, [3])\n",
    "\t\tg_state = slim.conv2d(g_state, 3, [3, 3], stride=1, padding='VALID',\n",
    "\t\t\tactivation_fn=tf.nn.tanh, normalizer_fn=None, scope='output')\n",
    "\treturn g_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243cc75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
