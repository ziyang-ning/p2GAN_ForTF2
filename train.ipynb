{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a205253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model       #written in tensorflow from the original\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import util        #written in tensorflow from the original\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob as glob\n",
    "from PIL import Image\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import vgg16part   #Have to change the cable\n",
    "\n",
    "#import that model:\n",
    "import import_ipynb\n",
    "import model\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b07a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load util functions\n",
    "\n",
    "ls_files_to_json = util.ls_files_to_json\n",
    "make_input_batch = util.make_input_batch # Patch Permutation\n",
    "open_img         = util.open_img\n",
    "pickup_list      = util.pickup_list\n",
    "images_batch     = util.images_batch\n",
    "load_cfg         = util.load_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build models\n",
    "build_generator     = model.build_generator\n",
    "build_discriminator = model.build_discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2827cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the pathch size, can be 9,12,15,16\n",
    "#MAX2KEEP, default = 10\n",
    "PATCH_SIZE   = 9\n",
    "MAX2KEEP  = 10\n",
    "CFG = 'cfg.json'\n",
    "supported_patch_size = {\n",
    "    9 : 216,\n",
    "    12: 240,\n",
    "    15: 240,\n",
    "    16: 256\n",
    "}\n",
    "# check args\n",
    "if not PATCH_SIZE in supported_patch_size:\n",
    "\texit(\"patch size not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed1297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the impoertant parameters\n",
    "# using the defalut values\n",
    "PSI_D_SIZE   = supported_patch_size[PATCH_SIZE]\n",
    "G_IMG_SIZE   = supported_patch_size[PATCH_SIZE]\n",
    "VGG_L        = 1\n",
    "VGG_FEATURES = 64\n",
    "\n",
    "BATCH_SIZE   = 8\n",
    "LAMBDA       = 5.0e-6\n",
    "\n",
    "##---------------TODO:: Fill in the paths--------------------\n",
    "MODEL_SAVE_PATH = 'available_models/'\n",
    "STYLE_IMG       = 'style/morncolour_whale.jpeg'\n",
    "TRAINSET_PATH   = 'archive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8433a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the image and show it\n",
    "style_img = open_img(STYLE_IMG)\n",
    "img2 = style_img[:,:,::-1]\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d50162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training process\n",
    "\n",
    "input_ls = ls_files_to_json(TRAINSET_PATH, ext=['png', 'bmp', 'jpg', 'jpeg'])\n",
    "TRAIN_SET = len(input_ls)\n",
    "print (TRAIN_SET)\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "# with tf.Session() as sess:\n",
    "\tinput_s = tf.placeholder(tf.float32, shape=[BATCH_SIZE, PSI_D_SIZE, PSI_D_SIZE, 3], name='inps')\n",
    "\tinput_c = tf.placeholder(tf.float32, shape=[BATCH_SIZE, G_IMG_SIZE, G_IMG_SIZE, 3], name='inpc')\n",
    "\n",
    "\tvgg_c = vgg16part.Vgg16()\n",
    "\twith tf.name_scope(\"content_vgg\"):\n",
    "\t\tvgg_c.build(input_c)\n",
    "\n",
    "\tg_state = build_generator(input_c, name='generator')\n",
    "\n",
    "\tvgg_g = vgg16part.Vgg16()\n",
    "\twith tf.name_scope(\"content_vgg\"):\n",
    "\t\tvgg_g.build(g_state)\n",
    "\n",
    "    #added reuse=tf.AUTO_REUSE for dp_real only\n",
    "\tdp_real = build_discriminator(input_s, patch_size=PATCH_SIZE, name='discriminator', reuse=tf.AUTO_REUSE)\n",
    "\tdp_fake = build_discriminator(g_state, patch_size=PATCH_SIZE, name='discriminator', reuse=True)\n",
    "\n",
    "\td_raw = vgg_c.prob # 128 * 128 * 64\n",
    "\td_gen = vgg_g.prob # 128 * 128 * 64\n",
    "\n",
    "\td_real_d = tf.reduce_mean(dp_real)\n",
    "\td_fake_d = tf.reduce_mean(dp_fake)\n",
    "\n",
    "\tmean_d_fake = tf.reduce_mean(dp_fake)\n",
    "\td_fake_g = tf.reduce_mean((dp_fake) ** (1.0 - (dp_fake - mean_d_fake)))\n",
    "\t# d_fake_g = tf.reduce_mean(dp_fake)\n",
    "\n",
    "\td_loss = -(tf.log(d_real_d) + tf.log(1 - d_fake_d))\n",
    "\tg_loss = (tf.norm(d_raw - d_gen) ** 2)*LAMBDA /(BATCH_SIZE*((G_IMG_SIZE/VGG_L)*(G_IMG_SIZE/VGG_L))*VGG_FEATURES)-tf.log(d_fake_g)\n",
    "\t# g_loss = tf.log(1 - d_fake_g) + (tf.norm(d_raw - d_gen) ** 2)*LAMBDA /(BATCH_SIZE*((G_IMG_SIZE/VGG_L)*(G_IMG_SIZE/VGG_L))*VGG_FEATURES)\n",
    "\n",
    "\td_var_ls = tf.trainable_variables(scope='discriminator')\n",
    "\t# train_step_d = tf.train.AdamOptimizer(learning_rate=2e-4, beta1=0.5, beta2=0.9).minimize(d_loss, var_list=d_var_ls)\n",
    "\tupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\twith tf.control_dependencies(update_ops):\n",
    "\t\ttrain_step_d = tf.train.RMSPropOptimizer(5e-4).minimize(d_loss, var_list=d_var_ls)\n",
    "\t# train_step_d = tf.train.GradientDescentOptimizer(1e-3).minimize(d_loss, var_list=d_var_ls)\n",
    "\n",
    "\tg_var_ls = tf.trainable_variables(scope='generator')\n",
    "\t# train_step_g = tf.train.AdamOptimizer(learning_rate=2e-4, beta1=0.5, beta2=0.9).minimize(g_loss, var_list=g_var_ls)\n",
    "\ttrain_step_g = tf.train.RMSPropOptimizer(5e-4).minimize(g_loss, var_list=g_var_ls)\n",
    "\t# train_step_g = tf.train.GradientDescentOptimizer(1e-3).minimize(g_loss, var_list=g_var_ls)\n",
    "\t\n",
    "\tsess.run(tf.global_variables_initializer())\n",
    "\tvar_ls = g_var_ls.append(d_var_ls)\n",
    "\tsaver = tf.train.Saver(tf.trainable_variables(scope='generator'), max_to_keep=MAX2KEEP)\n",
    "\tepoch = 0\n",
    "\ttrain_cfg = load_cfg(CFG)\n",
    "\tif train_cfg['load_model']:\n",
    "\t\tchkpt_fname = tf.train.latest_checkpoint(MODEL_SAVE_PATH)\n",
    "\t\tsaver.restore(sess, chkpt_fname)\n",
    "\twhile epoch < train_cfg['epoch_lim']:\n",
    "\t\ttrain_cfg = load_cfg(CFG)\n",
    "\t\trandom.shuffle(input_ls)\n",
    "\t\ttravx = int(TRAIN_SET / BATCH_SIZE) + (1 if (TRAIN_SET % BATCH_SIZE) != 0 else 0)\n",
    "\t\tfor offset in range(travx):\n",
    "\t\t\ttrain_cfg = load_cfg(CFG)\n",
    "\t\t\tsub_ls  = pickup_list(input_ls, BATCH_SIZE, offset * BATCH_SIZE)\n",
    "\t\t\tsub_img = images_batch(TRAINSET_PATH, sub_ls, prep=True,\n",
    "\t\t\t\t\t\t\t\tshape=(G_IMG_SIZE, G_IMG_SIZE), singleCh=False, remove_pad=True)\t\n",
    "\t\t\tfor td in range(train_cfg['D']['max_iter']):\n",
    "\t\t\t\tsess.run(train_step_d, feed_dict={\n",
    "\t\t\t\t\t\tinput_s: make_input_batch(style_img, BATCH_SIZE, PSI_D_SIZE, PSI_D_SIZE, PATCH_SIZE),\n",
    "\t\t\t\t\t\tinput_c: sub_img\n",
    "\t\t\t\t\t})\n",
    "\t\t\tfor tg in range(train_cfg['G']['max_iter']):\n",
    "\t\t\t\tsess.run(train_step_g, feed_dict={\n",
    "\t\t\t\t\t\tinput_c: sub_img\n",
    "\t\t\t\t\t})\n",
    "\t\t\tprint('epoch %04d'%epoch, 'InnerProcess: %d/%d'%(offset, travx))\n",
    "\n",
    "\t\t\tif train_cfg['preview']:\n",
    "\t\t\t\tif train_cfg['view_iter'] == offset:\n",
    "\t\t\t\t\tutil.silent_mkdir('preview/%d_%d'%(epoch, offset))\n",
    "\t\t\t\t\tutil.save_batch_as_rgb_img(sess.run(g_state,\n",
    "\t\t\t\t\t\tfeed_dict={input_c: sub_img}), 'preview/%d_%d'%(epoch, offset), prefix='0_')\n",
    "\t\t\tif train_cfg['save_model_iter'] == offset:\n",
    "\t\t\t\tsaver.save(sess, os.path.join(MODEL_SAVE_PATH, \"model\"), global_step=epoch)\n",
    "\n",
    "\n",
    "\t\tcur_d_real = sess.run(d_real_d, feed_dict={\n",
    "\t\t\t\tinput_s: make_input_batch(style_img, BATCH_SIZE, PSI_D_SIZE, PSI_D_SIZE, PATCH_SIZE),\n",
    "\t\t\t\tinput_c: sub_img\n",
    "\t\t\t})\n",
    "\t\tcur_d_fake = sess.run(d_fake_d, feed_dict={\n",
    "\t\t\t\tinput_c: sub_img\n",
    "\t\t\t})\n",
    "\t\tprint('\\33[1;32mEpoch %d D_TURN D real\\33[0m = '%epoch, cur_d_real.mean())\n",
    "\t\tprint('\\33[1;31mEpoch %d D_TURN D fake\\33[0m = '%epoch, cur_d_fake.mean())\n",
    "\t\tif epoch % train_cfg['export'] == 0:\n",
    "\t\t\tutil.silent_mkdir('preview/%d'%epoch)\n",
    "\t\t\tutil.save_batch_as_rgb_img(sess.run(g_state,\n",
    "\t\t\t\tfeed_dict={input_c: sub_img}), 'preview/%d'%epoch, prefix='0_')\n",
    "\t\tif (epoch % train_cfg['save_step'] == 0 or epoch == train_cfg['save_at']):\n",
    "\t\t\tsaver.save(sess, os.path.join(MODEL_SAVE_PATH, \"model\"), global_step=epoch)\n",
    "\t\tepoch = epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e79aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
