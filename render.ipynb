{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b1f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 19:56:46.205871: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from model.ipynb\n"
     ]
    }
   ],
   "source": [
    "#the imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import util\n",
    "import time\n",
    "#import that model:\n",
    "import import_ipynb\n",
    "import model\n",
    "\n",
    "import os\n",
    "#from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad970368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The parameters\n",
    "imbatch_read     = util.imbatch_read\n",
    "img_write        = util.img_write\n",
    "pickup_list      = util.pickup_list\n",
    "ls_files_to_json = util.ls_files_to_json\n",
    "\n",
    "build_generator     = model.build_generator\n",
    "\n",
    "# args = build_parser().parse_args()\n",
    "\n",
    "#-----------------TODO: LOAD YOU MODEL AND IMAGES HERE-------------\n",
    "MODEL_SAVE_PATH = 'available_models/anime/'\n",
    "OUT_PATH = 'rendered_images/anime_pics/'\n",
    "IMGSRC_PATH = 'test_images/'\n",
    "\n",
    "if (not os.path.isdir(OUT_PATH)):\n",
    "\tos.makedirs(OUT_PATH)\n",
    "\n",
    "\n",
    "BATCH_SIZE  = 1\n",
    "FEED_SIZE   = 256\n",
    "NOISE_RATE  = 0\n",
    "#use_cpu, you can set this to True if GPU is not available\n",
    "USE_CPU = False\n",
    "\n",
    "DEVICE = ''\n",
    "if USE_CPU =='TRUE':\n",
    "\tDEVICE = '/cpu:0'\n",
    "    \n",
    "input_ls = ls_files_to_json(IMGSRC_PATH, ext=['png', 'bmp', 'jpg', 'jpeg'])\n",
    "CNT = len(input_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f543927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 19:56:49.071092: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-22 19:56:49.071438: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-04-22 19:56:49.082728: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-22 19:56:49.082750: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/ziyangning/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-04-22 19:56:49.308714: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from available_models/anime/model-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 19:56:49.762113: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-22 19:56:49.812036: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 1/9, network dataflow time: 0.032925\n",
      "Processing: 2/9, network dataflow time: 0.029635\n",
      "Processing: 3/9, network dataflow time: 0.030943\n",
      "Processing: 4/9, network dataflow time: 0.028031\n",
      "Processing: 5/9, network dataflow time: 0.030092\n",
      "Processing: 6/9, network dataflow time: 0.027685\n",
      "Processing: 7/9, network dataflow time: 0.027574\n",
      "Processing: 8/9, network dataflow time: 0.030295\n",
      "Processing: 9/9, network dataflow time: 0.029714\n"
     ]
    }
   ],
   "source": [
    "#start the render process\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "\n",
    "with tf.device(DEVICE), tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "\tinput_r = tf.placeholder(tf.float32, shape=[BATCH_SIZE, FEED_SIZE, FEED_SIZE, 3], name='inpr')\n",
    "\tg_state = build_generator(input_r, name='generator')\n",
    "\tg_var_ls = tf.trainable_variables(scope='generator')\n",
    "\tsess.run(tf.global_variables_initializer())\n",
    "\tsaver = tf.train.Saver(g_var_ls)\n",
    "\tchkpt_fname = tf.train.latest_checkpoint(MODEL_SAVE_PATH)\n",
    "\tsaver.restore(sess, chkpt_fname)\n",
    "\t# Warm up network and test...\n",
    "\tnoise = np.random.normal(0, 1, size=(BATCH_SIZE, FEED_SIZE, FEED_SIZE, 3)).astype(np.float32)\n",
    "\tsess.run(g_state, feed_dict={input_r: noise})\n",
    "\t# Begin...\n",
    "\ttotal = int(CNT / BATCH_SIZE) + (1 if (CNT % BATCH_SIZE) != 0 else 0)\n",
    "\tfor offset in range(total):\n",
    "\t\tsub_ls  = pickup_list(input_ls, BATCH_SIZE, offset * BATCH_SIZE)\n",
    "\t\tsub_img, sls = imbatch_read(IMGSRC_PATH, sub_ls, (FEED_SIZE, FEED_SIZE))\n",
    "\t\tif NOISE_RATE != 0:\n",
    "\t\t\tnoise = np.random.normal(0, 1,\n",
    "\t\t\t\tsize=(BATCH_SIZE, FEED_SIZE, FEED_SIZE, 3)).astype(np.float32)\n",
    "\t\t\tsub_img = sub_img + noise * NOISE_RATE \n",
    "\t\ttime_start = time.time()\n",
    "\t\trender_batch = sess.run(g_state, feed_dict={input_r: sub_img})\n",
    "\t\tprint('Processing: %d/%d, network dataflow time: %f'%(offset + 1, total, time.time()-time_start))\n",
    "\t\tfor i in range(len(sls)):\n",
    "\t\t\timg_write(render_batch[i],\n",
    "\t\t\t\t\tOUT_PATH+'/%d_%d.jpg'%(offset, i),\n",
    "\t\t\t\tsls[i])# (FEED_SIZE, FEED_SIZE)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdef918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
